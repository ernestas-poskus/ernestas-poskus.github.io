<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>paper on Ernestas Poškus technical blog</title>
    <link>http://out13.com/tags/paper/</link>
    <description>Recent content in paper on Ernestas Poškus technical blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 23 May 2021 07:19:49 +0300</lastBuildDate>
    
	<atom:link href="http://out13.com/tags/paper/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Wormhole: Reliable Pub-Sub to Support Geo-replicated Internet Services</title>
      <link>http://out13.com/paper/reliable-pub-sub-to-support-geo-replicated-internet-services/</link>
      <pubDate>Sun, 23 May 2021 07:19:49 +0300</pubDate>
      
      <guid>http://out13.com/paper/reliable-pub-sub-to-support-geo-replicated-internet-services/</guid>
      <description>Wormhole Wormhole is a publish-subscribe (pub-sub) system developed for use within Facebook’s geographically replicated datacenters. It is used to reliably replicate changes among several Facebook services including TAO, Graph Search and Memcache.
Facebook production deployment of Wormhole transfers over 35 GBytes/sec in steady state (50 millions messages/sec or 5 trillion messages/day) across all deployments with bursts up to 200 GBytes/sec during failure recovery.
Wormhole, a pub-sub system that identifies new writes and publishes updates to all interested applications.</description>
    </item>
    
    <item>
      <title>Swim Scalable Weakly Consistent Infection Style Process Group Membership Protocol</title>
      <link>http://out13.com/paper/swim-scalable-weakly-consistent-infection-style-process-group-membership-protocol/</link>
      <pubDate>Fri, 14 May 2021 20:01:12 +0300</pubDate>
      
      <guid>http://out13.com/paper/swim-scalable-weakly-consistent-infection-style-process-group-membership-protocol/</guid>
      <description>SWIM Distributed peer-to-peer applications require weakly-consistent knowledge of process group membership information at all participating processes.
SWIM separates the failure detection and membership update dissemination functionalities of the membership protocol.
Swim focus on a weaker variant of group membership, where membership lists at different members need not be consistent across the group at the same (causal) point in time.
The design of a distributed membership algorithm has traditionally been approached through the technique of heart-beating.</description>
    </item>
    
    <item>
      <title>Harvest Yield and Scalable Tolerant Systems</title>
      <link>http://out13.com/paper/harvest-yield-and-scalable-tolerant-systems/</link>
      <pubDate>Fri, 07 May 2021 18:40:52 +0300</pubDate>
      
      <guid>http://out13.com/paper/harvest-yield-and-scalable-tolerant-systems/</guid>
      <description>Scalable tolerant systems Degradation in terms of harvest and yield, and map it directly onto engineering mechanisms that enhance availability by improving fault isolation, and in some cases also simplify programming.
CA without P: Databases that provide distributed transactional semantics can only do so in the absence of a network partition separating server peers.
CP without A: In the event of a partition, further transactions to an ACID database may be blocked until the partition heals, to avoid the risk of introducing merge conflicts (and thus inconsistency).</description>
    </item>
    
    <item>
      <title>Availability in Globally Distributed Storage Systems</title>
      <link>http://out13.com/paper/availability-in-globally-distributed-storage-systems/</link>
      <pubDate>Thu, 06 May 2021 20:21:50 +0300</pubDate>
      
      <guid>http://out13.com/paper/availability-in-globally-distributed-storage-systems/</guid>
      <description>Highly available cloud storage is often implemented with complex, multi-tiered distributed systems built on top of clusters of commodity servers and disk drives. Sophisticated management, load balancing and recovery techniques are needed to achieve high performance and availability amidst an abundance of failure sources that include software, hardware, network connectivity, and power issues.
Component availability  Compare mean time to failure for system components at different granularities, including disks, machines and racks of machines.</description>
    </item>
    
    <item>
      <title>A Five Stage Model of the Mental Activities Involved in Directed Skill Acquisition</title>
      <link>http://out13.com/paper/five-stage-model-of-the-mental-activities-involved-in-directed-skill-acquisition/</link>
      <pubDate>Thu, 06 May 2021 19:31:13 +0300</pubDate>
      
      <guid>http://out13.com/paper/five-stage-model-of-the-mental-activities-involved-in-directed-skill-acquisition/</guid>
      <description>Five-stage model of the mental activities In acquiring a skill by means of instruction and experience, the student normally passes through five develop- mental stages which we designate novice, competence, proficiency, expertise and mastery.
As the student becomes skilled, he depends less on abstract principles and more on concrete experience.
Two options to pick a skill:
 like a baby, pick it up by imitation and floundering trial-and-error aid of an instructor or instruction manual  Erroneous information obtained by scientific methods (and therefore having an aura of truth) is more harmful than no information at all.</description>
    </item>
    
    <item>
      <title>IO with io_uring</title>
      <link>http://out13.com/paper/efficient-io-with-io-uring/</link>
      <pubDate>Tue, 09 Jun 2020 20:55:21 +0300</pubDate>
      
      <guid>http://out13.com/paper/efficient-io-with-io-uring/</guid>
      <description>IO history There are many ways to do file based IO in Linux. The oldest and most basic are the read(2) and write(2) system calls. These were later augmented with pread(2) and pwrite(2) versions which allow passing in of an offset, and later still we got preadv(2) and pwritev(2) which are vector-based versions of the former. Because that still wasn&amp;rsquo;t quite enough, Linux also has preadv2(2) and pwritev2(2) system calls, which further extend the API to allow modifier flags.</description>
    </item>
    
    <item>
      <title>Amplification Hell: Revisiting Network Protocols for DDoS Abuse</title>
      <link>http://out13.com/paper/amplification-hell-revisiting-network-protocols-for-ddos-abuse/</link>
      <pubDate>Sun, 06 Jan 2019 11:35:06 +0200</pubDate>
      
      <guid>http://out13.com/paper/amplification-hell-revisiting-network-protocols-for-ddos-abuse/</guid>
      <description>Amplification attacks Adversaries send requests to public servers (e.g., open recursive DNS resolvers) and spoof the IP address of a victim. These servers, in turn, flood the victim with valid responses and – unknowingly – exhaust its bandwidth.
Attackers can abuse these protocols to multiply their attack bandwidth by factors from 3.8 (BitTorrent, NetBios) up to 4670 (NTP).
Exclude all TCP-based protocols from our analysis, as IP address spoofing is restricted to the start of the TCP handshake.</description>
    </item>
    
    <item>
      <title>Uniqueness and Reference Immutability for Safe Parallelism</title>
      <link>http://out13.com/paper/uniqueness-and-reference-immutability-for-safe-parallelism/</link>
      <pubDate>Thu, 29 Mar 2018 20:00:23 +0300</pubDate>
      
      <guid>http://out13.com/paper/uniqueness-and-reference-immutability-for-safe-parallelism/</guid>
      <description>Key challenge for concurrent programming is that side-effects (memory operations) in one thread can affect the behavior of another thread.
We wish to restrict, or tame, side-effects to make programs easier to maintain and understand. To do so, we build on reference immutability.
To achieve this we give two novel typing rules, which allow recovering isolated or immutable references from arbitrary code checked in environments containing only isolated or immutable inputs.</description>
    </item>
    
    <item>
      <title>Write Behind Logging</title>
      <link>http://out13.com/paper/write-behind-logging/</link>
      <pubDate>Thu, 11 Jan 2018 19:27:57 +0200</pubDate>
      
      <guid>http://out13.com/paper/write-behind-logging/</guid>
      <description>WBL vs WAL Design of the logging and recovery components of database management systems (DBMSs) has always been influenced by the difference in the performance characteristics of volatile (DRAM) and non-volatile storage devices (HDD/SSDs). The key assumption has been that non-volatile storage is much slower than DRAM and only supports block-oriented read/writes. But the arrival of new nonvolatile memory (NVM) storage that is almost as fast as DRAM with fine-grained read/writes invalidates these previous design choices.</description>
    </item>
    
    <item>
      <title>B4: Experience with a Globally-Deployed Software Defined WAN</title>
      <link>http://out13.com/paper/b4-software-defined-wan/</link>
      <pubDate>Sun, 07 Jan 2018 11:32:25 +0200</pubDate>
      
      <guid>http://out13.com/paper/b4-software-defined-wan/</guid>
      <description>Software defined WAN B4, a private WAN connecting Google’s data centers across the planet.
i) Massive bandwidth requirements deployed to a modest number of sites.
ii) Elastic traffic demand that seeks to maximize average bandwidth.
iii) Full control over the edge servers and network, which enables rate limiting and demand measurement at the edge.
Design Within each B4 site, the switch hardware layer primarily forwards traffic and does not run complex control software, and the site controller layer consists of Network Control Servers (NCS) hosting both OpenFlow controllers (OFC) and Network Control Applications (NCAs).</description>
    </item>
    
    <item>
      <title>Overcoming catastrophic forgetting in neural networks</title>
      <link>http://out13.com/paper/overcoming-catastrophic-forgetting-in-neural-networks/</link>
      <pubDate>Sun, 12 Nov 2017 23:05:18 +0200</pubDate>
      
      <guid>http://out13.com/paper/overcoming-catastrophic-forgetting-in-neural-networks/</guid>
      <description>Catastrophic forgetting in neural networks The ability to learn tasks in a sequential fashion is crucial to the development of artificial intelligence. Neural networks are not, in general, capable of this and it has been widely thought that catastrophic forgetting is an inevitable feature of connectionist models.
It is possible to overcome this limitation.
Our approach remembers old tasks by selectively slowing down learning on the weights important for those tasks.</description>
    </item>
    
    <item>
      <title>Bitcoin a Peer to Peer Electronic Cash System</title>
      <link>http://out13.com/paper/bitcoin-a-peer-to-peer-electronic-cash-system/</link>
      <pubDate>Thu, 19 Oct 2017 20:23:22 +0300</pubDate>
      
      <guid>http://out13.com/paper/bitcoin-a-peer-to-peer-electronic-cash-system/</guid>
      <description>P2P Electronic Cash System A purely peer-to-peer version of electronic cash would allow online payments to be sent directly from one party to another without going through a financial institution.
Prevent double-spending problem using a peer-to-peer network.
As long as a majority of CPU power is controlled by nodes that are not cooperating to attack the network, they&amp;rsquo;ll generate the longest chain and outpace attackers.
The system is secure as long as honest nodes collectively control more CPU power than any cooperating group of attacker nodes.</description>
    </item>
    
    <item>
      <title>Attacking Branch Predictors to Bypass ASLR</title>
      <link>http://out13.com/paper/jump-over-aslr-attacking-branch-predictors-to-bypass-aslr/</link>
      <pubDate>Thu, 14 Sep 2017 19:48:19 +0300</pubDate>
      
      <guid>http://out13.com/paper/jump-over-aslr-attacking-branch-predictors-to-bypass-aslr/</guid>
      <description>Address Space Layout Randomization ASLR is widely used technique that protects systems against range of attacks.
ASLR works by randomizing the offset of key program segments in virtual memory, making it difficult for an attacker to derive the addresses of specific code objects and consequently redirect the control flow to this code.
Purpose of ASLR is to make it difficult, if not impossible, for the attacker to know the location of specific code pages in program address space.</description>
    </item>
    
    <item>
      <title>Cooperative Task Management without Manual Stack Management</title>
      <link>http://out13.com/paper/cooperative-task-management-without-manual-stack-management/</link>
      <pubDate>Thu, 10 Aug 2017 21:48:19 +0300</pubDate>
      
      <guid>http://out13.com/paper/cooperative-task-management-without-manual-stack-management/</guid>
      <description>Or, Event-driven Programming is Not the Opposite of Threaded Programming Two programming styles as a conflation of two concepts: task management and stack management.
Those two concerns define a two-axis space in which &amp;lsquo;multithreaded&amp;rsquo; and &amp;lsquo;event-driven&amp;rsquo; programming are diagonally opposite; there is a third &amp;lsquo;sweet spot&amp;rsquo; in the space that combines the advantages of both programming styles.
Different task management approaches offer different granularities of atomicity on shared state. Conflict management considers how to convert available atomicity to a meaningful mechanism for avoiding resource conflicts.</description>
    </item>
    
    <item>
      <title>Analyzing the Security of Traffic Infrastructure</title>
      <link>http://out13.com/paper/green-lights-forever-analyzing-the-security-of-traffic-infrastructure/</link>
      <pubDate>Thu, 03 Aug 2017 19:10:33 +0300</pubDate>
      
      <guid>http://out13.com/paper/green-lights-forever-analyzing-the-security-of-traffic-infrastructure/</guid>
      <description>Green Lights Forever Safety critical nature of traffic infrastructure requires that it be secure against computer-based attacks.
Traffic signals were originally designed as standalone hardware, each running on fixed timing schedules, but have evolved into more complex, networked systems.
Traffic controllers now store multiple timing plans, integrate varied sensor data, and even communicate with other intersections in order to better coordinate traffic.
Wireless networking has helped to mitigate these costs, and many areas now use intelligent wireless traffic management systems.</description>
    </item>
    
    <item>
      <title>Scaling Memcache at Facebook</title>
      <link>http://out13.com/paper/scaling-memcache-at-facebook/</link>
      <pubDate>Thu, 27 Jul 2017 19:47:58 +0300</pubDate>
      
      <guid>http://out13.com/paper/scaling-memcache-at-facebook/</guid>
      <description>Memcache at Facebook Largest memcached installation in the world, processing over a billion requests per second and storing trillions of items.
Items are distributed across the memcached servers through consistent hashing.
all web servers communicate with every memcached server in a short period of time. This all-to-all communication pattern can cause incast congestion or allow a single server to become the bottleneck for many web servers. Reduce latency mainly by focusing on the memcache client, which runs on each web server.</description>
    </item>
    
    <item>
      <title>Maglev: A Fast and Reliable Software Network Load Balancer</title>
      <link>http://out13.com/paper/maglev-a-fast-and-reliable-software-network-load-balancer/</link>
      <pubDate>Thu, 29 Jun 2017 18:11:57 +0300</pubDate>
      
      <guid>http://out13.com/paper/maglev-a-fast-and-reliable-software-network-load-balancer/</guid>
      <description>Maglev - fast and reliable network balancer Packets are distributed through ECMP.
Serves traffic for Google services &amp;amp; GCP.
Every Google service has 1 or more VIP&amp;rsquo;s.
Maglev associates each VIP with a set of service endpoints and announces it to the router over BGP. The router, in turn, announces the VIP to Google backbone.
Router receives a VIP packet it forwards the packet to 1 of Maglev machines in the cluster through ECMP since all Maglev machines announce the VIP with the same cost.</description>
    </item>
    
    <item>
      <title>Spanner: Google’s Globally-Distributed Database</title>
      <link>http://out13.com/paper/spanner-google-globally-distributed-database/</link>
      <pubDate>Thu, 25 May 2017 19:53:19 +0300</pubDate>
      
      <guid>http://out13.com/paper/spanner-google-globally-distributed-database/</guid>
      <description>Spanner Spanner is a scalable, globally-distributed database designed, built, and deployed at Google.
At the highest level of abstraction, it is a database that shards data across many sets of Paxos state machines.
Replication is used for global availability and geographic locality.
Spanner is designed to scale up to millions of machines across hundreds of datacenters and trillions of database rows.
Data is stored in schematized semi-relational tables; data is versioned, and each version is automatically timestamped with its commit time; old versions of data are subject to configurable garbage-collection policies; and applications can read data at old timestamps.</description>
    </item>
    
    <item>
      <title>In Search of an Understandable Consensus Algorithm</title>
      <link>http://out13.com/paper/in-search-of-an-understandable-consensus-algorithm/</link>
      <pubDate>Thu, 20 Apr 2017 19:13:57 +0300</pubDate>
      
      <guid>http://out13.com/paper/in-search-of-an-understandable-consensus-algorithm/</guid>
      <description>Raft Consensus algorithm for managing a replicated log.
Raft separates the key elements of consensus, such as leader election, log replication, and safety, and it enforces a stronger degree of coherency to reduce the number of states that must be considered.
Paxos first defines a protocol capable of reaching agreement on a single decision, such as a single replicated log entry.
Raft implements consensus by first electing a distinguished leader, then giving the leader complete responsibility for managing the replicated log.</description>
    </item>
    
    <item>
      <title>LIRS: An Efficient Low Inter-reference Recency Set Replacement Policy to Improve Buffer Cache Performance</title>
      <link>http://out13.com/paper/lirs-efficient-low-inter-reference-recency-set-replacement-policy-to-improve-buffer-cache-performance/</link>
      <pubDate>Thu, 09 Mar 2017 19:34:52 +0200</pubDate>
      
      <guid>http://out13.com/paper/lirs-efficient-low-inter-reference-recency-set-replacement-policy-to-improve-buffer-cache-performance/</guid>
      <description>LIRS LRU replacement policy has been commonly used in the buffer cache management, it is well known for its inability to cope with access patterns with weak locality.
LIRS effectively addresses the limits of LRU by using recency to evaluate Inter-Reference Recency (IRR) for making a replacement decision.
LRU inefficiency   Under the LRU policy, a burst of references to infrequently used blocks such as “sequential scans” through a large file, may cause replacement of commonly referenced blocks in the cache.</description>
    </item>
    
    <item>
      <title>Large-scale cluster management at Google with Borg</title>
      <link>http://out13.com/paper/large-scale-cluster-management-at-google-with-borg/</link>
      <pubDate>Thu, 09 Feb 2017 20:27:52 +0200</pubDate>
      
      <guid>http://out13.com/paper/large-scale-cluster-management-at-google-with-borg/</guid>
      <description>Borg Cluster manager that runs hundreds of thousands of jobs, from many thousands of different applications, across a number of clusters each with up to tens of thousands of machines.
3 main benefits:
 hides the details of resource management and failure handling so its users can focus on application development instead operates with very high reliability and availability, and supports applications that do the same lets us run workloads across tens of thousands of machines effectively  A key design feature in Borg is that already-running tasks continue to run even if the Borgmaster or a task’s Borglet goes down.</description>
    </item>
    
    <item>
      <title>Aerospike: Architecture of a Real-Time Operational DBMS</title>
      <link>http://out13.com/paper/aerospike-architecture-of-a-real-time-operational-dbms/</link>
      <pubDate>Sun, 29 Jan 2017 13:47:18 +0200</pubDate>
      
      <guid>http://out13.com/paper/aerospike-architecture-of-a-real-time-operational-dbms/</guid>
      <description>Aerospike architecture Modeled on the classic shared-nothing database architecture
Objectives of the cluster management subsystem:
 Arrive at a single consistent view of current cluster members across all nodes in the cluster. Automatically detect new node arrival/departure and seamless cluster reconfiguration. Detect network faults and be resilient to such network flakiness. Minimize time to detect and adapt to cluster membership changes.  Discovery Node arrival or departure is detected via heartbeat messages exchanged periodically between nodes.</description>
    </item>
    
    <item>
      <title>Approximating Data with the Count-Min Data Structure</title>
      <link>http://out13.com/paper/approximating-data-with-the-count-min-data-structure/</link>
      <pubDate>Thu, 29 Dec 2016 20:25:26 +0200</pubDate>
      
      <guid>http://out13.com/paper/approximating-data-with-the-count-min-data-structure/</guid>
      <description>Count-Min Data Structure Algorithmic problems such as tracking the contents of a set arise frequently in the course of building systems. Given the variety of possible solutions, the choice of appropriate data structures for such tasks is at the heart of building efficient and effective software.
The Count-Min sketch provides a different kind of solution to count tracking. It allocates a fixed amount of space to store count information, which does not vary over time even as more and more counts are updated.</description>
    </item>
    
    <item>
      <title>TAO: Facebook’s Distributed Data Store for the Social Graph</title>
      <link>http://out13.com/paper/tao-facebooks-distributed-data-store-for-the-social-graph/</link>
      <pubDate>Thu, 15 Dec 2016 19:36:32 +0200</pubDate>
      
      <guid>http://out13.com/paper/tao-facebooks-distributed-data-store-for-the-social-graph/</guid>
      <description>Distributed data store for social graph TAO is geographically distributed data store that provides efficient and timely access to the social graph using a fixed set of queries. Read optimized, persisted in MySQL.
Inefficient edge lists: A key-value cache is not a good semantic fit for lists of edges; queries must always fetch the entire edge list and changes to a single edge require the entire list to be reloaded.</description>
    </item>
    
    <item>
      <title>Efficient Reconciliation and Flow Control for Anti-Entropy Protocols</title>
      <link>http://out13.com/paper/efficient-reconciliation-and-flow-control-for-anti-entropy-protocols/</link>
      <pubDate>Thu, 01 Dec 2016 16:05:39 +0200</pubDate>
      
      <guid>http://out13.com/paper/efficient-reconciliation-and-flow-control-for-anti-entropy-protocols/</guid>
      <description>Flow Gossip Anti-entropy, or gossip, is an attractive way of replicating state that does not have strong consistency requirements. With few limitations, updates spread in expected time that grows logarithmic in the number of participating hosts, even in the face of host failures and message loss. The behavior of update propagation is easily modeled with well-known epidemic analysis techniques.
Gossip basics There are two classes of gossip: anti-entropy and rumor mongering protocols.</description>
    </item>
    
    <item>
      <title>SEDA: An Architecture for Well-Conditioned, Scalable Internet Services</title>
      <link>http://out13.com/paper/seda-an-architecture-for-well-conditioned-scalable-internet-services/</link>
      <pubDate>Thu, 24 Nov 2016 19:50:13 +0200</pubDate>
      
      <guid>http://out13.com/paper/seda-an-architecture-for-well-conditioned-scalable-internet-services/</guid>
      <description>SEDA - staged event driven architecture A SEDA is intended to support massive concurrency demands and simplify the construction of well-conditioned services. In SEDA, applications consist of a network of event-driven stages connected by explicit queues. This architecture allows services to be well-conditioned to load, preventing resources from being overcommitted when demand exceeds service capacity.
SEDA combines aspects of threads and event-based programming models to manage the concurrency, I/O, scheduling, and resource management needs of Internet services.</description>
    </item>
    
    <item>
      <title>The Interaction of Buffer Size and TCP Protocol Handling and its Impact</title>
      <link>http://out13.com/paper/the-interaction-of-buffer-size-and-tcp-protocol-handling/</link>
      <pubDate>Thu, 17 Nov 2016 19:23:07 +0200</pubDate>
      
      <guid>http://out13.com/paper/the-interaction-of-buffer-size-and-tcp-protocol-handling/</guid>
      <description>Abstract Miercom was engaged by Cisco Systems to conduct independent testing of two vendors’ top of the line, data-center switch-routers, including the Cisco Nexus 92160YC-X and Nexus 9272Q switches and the Arista 7280SE-72 switch.
TCP Congestion Control versus System Buffer Management TCP congestion control. The Transmission Control Protocol (TCP) is the Layer-4 control protocol (atop IP at Layer 3) that ensures a block of data that’s sent is received intact. Invented 35 years ago, TCP handles how blocks of data are broken up, sequenced, sent, reconstructed and verified at the recipient’s end.</description>
    </item>
    
    <item>
      <title>Replication Under Scalable Hashing: A Family of Algorithms for Scalable Decentralized Data Distribution</title>
      <link>http://out13.com/paper/replication-under-scalable-hashing-a-family-of-algorithms-for-scalable-decentralized-data-distribution/</link>
      <pubDate>Thu, 10 Nov 2016 22:27:23 +0200</pubDate>
      
      <guid>http://out13.com/paper/replication-under-scalable-hashing-a-family-of-algorithms-for-scalable-decentralized-data-distribution/</guid>
      <description>Replication Under Scalable Hashing Typical algorithms for decentralized data distribution work best in a system that is fully built before it first used; adding or removing components results in either extensive reorganization of data or load imbalance in the system.
RUSH variants also support weighting, allowing disks of different vintages to be added to a system.
RUSH variants is optimal or near-optimal reorganization. When new disks are added to the system, or old disks are retired, RUSH variants minimize the number of objects that need to be moved in order to bring the system back into balance.</description>
    </item>
    
    <item>
      <title>Dynamo: Amazon’s Highly Available Key-value Store</title>
      <link>http://out13.com/paper/dynamo-amazon-highly-available-key-value-store/</link>
      <pubDate>Sun, 06 Nov 2016 12:32:44 +0200</pubDate>
      
      <guid>http://out13.com/paper/dynamo-amazon-highly-available-key-value-store/</guid>
      <description>Dynamo Dynamo sacrifices Consistency for Availability under certain failure scenarios. It makes extensive use of object versioning and application-assisted conflict resolution in a manner that provides a novel interface for developers to use.
Gossip based distributed failure detection and membership protocol.
Query Model Read &amp;amp; Write operations to data item that is uniquely identified by a key. State is stored as blobs. Targets application that store objects up to 1MB.</description>
    </item>
    
    <item>
      <title>Bigtable: A Distributed Storage System for Structured Data</title>
      <link>http://out13.com/paper/bigtable-a-distributed-storage-system-for-structured-data/</link>
      <pubDate>Thu, 03 Nov 2016 19:54:45 +0200</pubDate>
      
      <guid>http://out13.com/paper/bigtable-a-distributed-storage-system-for-structured-data/</guid>
      <description>Bigtable Bigtable is a distributed storage system for managing structured data that is designed to scale to a very large size: petabytes of data across thousands of commodity servers.
Bigtable does not support a full relational data model; instead, it provides clients with a simple data model that supports dynamic control over data layout and format, and allows clients to reason about the locality properties of the data represented in the underlying storage.</description>
    </item>
    
    <item>
      <title>Ownership is theft experiences building an embedded os in rust</title>
      <link>http://out13.com/paper/ownership-is-theft-experiences-building-an-embedded-os-in-rust/</link>
      <pubDate>Thu, 25 Aug 2016 20:39:03 +0300</pubDate>
      
      <guid>http://out13.com/paper/ownership-is-theft-experiences-building-an-embedded-os-in-rust/</guid>
      <description>Embedded OS in Rust Embedded systems:
 lack hardware protection mechanism less tolerant to crashes no easy way for debugging GC introduces non-deterministic delay  Rust Rust, a new systems programming language, provides compile-time memory safety checks to help eliminate runtime bugs that manifest from improper memory management.
Rust’s ownership model prevents otherwise safe resource sharing common in the embedded domain, conflicts with the reality of hardware resources, and hinders using closures for programming asynchronously.</description>
    </item>
    
    <item>
      <title>On the fly garbage collection</title>
      <link>http://out13.com/paper/on-the-fly-garbage-collection/</link>
      <pubDate>Thu, 25 Aug 2016 19:13:56 +0300</pubDate>
      
      <guid>http://out13.com/paper/on-the-fly-garbage-collection/</guid>
      <description>In our abstract form of the problem, we consider a directed graph of varying structure but with a fixed number of nodes, in which each node has at most two outgoing edges. More precisely, each node may have a left-hand outgoing edge and may have a right-hand outgoing edge, but either of them or both may be missing. In this graph a fixed set of nodes exists, called &amp;ldquo;the roots.&amp;rdquo; A node is called &amp;ldquo;reachable&amp;rdquo; if it is reachable from at least one root via a directed path along the edges.</description>
    </item>
    
    <item>
      <title>Queues Are Databases</title>
      <link>http://out13.com/paper/queues-are-databases/</link>
      <pubDate>Fri, 12 Aug 2016 16:57:55 +0300</pubDate>
      
      <guid>http://out13.com/paper/queues-are-databases/</guid>
      <description>Queued transaction processing over pure client-server transaction processing. Queued systems are build on top of direct systems.
TP systems offer both queued and direct transaction processing. They offer both client-server and P2P direct processing.
Queue manager is best built as a naive resource manager atop an object-relational database system. That system must have good concurrency control, recovery, triggers, security, operations interfaces, and utilities.
Queues pose difficult problems when implemented atop a database:</description>
    </item>
    
    <item>
      <title>An Argument for Increasing TCP’s Initial Congestion Window</title>
      <link>http://out13.com/paper/an-argument-for-increasing-tcp-initial-congestion-window/</link>
      <pubDate>Thu, 04 Aug 2016 22:02:54 +0300</pubDate>
      
      <guid>http://out13.com/paper/an-argument-for-increasing-tcp-initial-congestion-window/</guid>
      <description>TCP congestion window  TCP flows start with initial congestion window of 4 segments (4KB of data).
 Window if critical for how quickly flows can finish.
Increase in 15KB congestion window improves average HTTP latency by 10%, mostly benefits RTT and BDP.
Slow start increases congestion window by the number of data segments acknowledged for each received ACK.
TCP latency is dominated by the number of round-trip times in slow-start phase.</description>
    </item>
    
    <item>
      <title>Mesos: A Platform for Fine-Grained Resource Sharing in the Data Center</title>
      <link>http://out13.com/paper/mesos-platform-for-resource-sharing/</link>
      <pubDate>Thu, 28 Apr 2016 19:50:29 +0300</pubDate>
      
      <guid>http://out13.com/paper/mesos-platform-for-resource-sharing/</guid>
      <description>Platform for resource sharing  Sharing improves cluster utilization and avoids per-framework data repli-cation Organizations will want to run multiple frameworks in the same cluster, picking the best one for each application. Sharing a cluster between frameworks improves utilization and allows applications to share access to large datasets that may be too costly to replicate
 Architecture Mesos decides how many resources to offer each framework, based on an organizational policy such as fair sharing, while frameworks decide which resources to accept and which tasks to run on them.</description>
    </item>
    
    <item>
      <title>Tiny LFU highly efficient cache admission policy</title>
      <link>http://out13.com/paper/tiny-lfu-highly-efficient-cache-admission-policy/</link>
      <pubDate>Fri, 22 Apr 2016 21:26:15 +0300</pubDate>
      
      <guid>http://out13.com/paper/tiny-lfu-highly-efficient-cache-admission-policy/</guid>
      <description>Frequency based cache admission policy  Approximate LFU structure called TinyLFU, which maintains an approximate representation of the access frequency of a large sample of recently accessed items.
 TinyLFU is very compact and light-weight as it builds upon Bloom filter theory.
Usage The intuitive reason why caching works is that data accesses in many domains of computer science exhibit a considerable degree of “locality”.
When a data item is accessed, if it already appears in the cache, we say that there is a cache hit; otherwise, it is a cache miss.</description>
    </item>
    
    <item>
      <title>Container based operating system virtualization</title>
      <link>http://out13.com/paper/container-based-operating-system-virtualization/</link>
      <pubDate>Tue, 19 Apr 2016 19:30:48 +0300</pubDate>
      
      <guid>http://out13.com/paper/container-based-operating-system-virtualization/</guid>
      <description>Alternative to hypervisors.  Workload requirements for a given system will direct users to the point in the design space that requires the least trade-off.
 Sharing over isolation? Hypervisors often deployed to let a single machine host multiple, unrelated applications, which may run on behalf of independent organizations, as is common when a data center consolidates multiple physical servers. Hypervisors favor full isolation over sharing. However, when each virtual machine is running the same kernel and similar operating system distributions, the degree of isolation offered by hypervisors comes at the cost of efficiency relative to running all applications on a single kernel.</description>
    </item>
    
  </channel>
</rss>